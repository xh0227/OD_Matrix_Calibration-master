{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules.\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from od_cal_cls.pca_spsa import pca_spsa\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up plotting templete.\n",
    "tempelete_01_white = dict(\n",
    "    layout = go.Layout(\n",
    "        # Layout properties\n",
    "        title_font_size= 14,\n",
    "        title_x= 0.1,\n",
    "        font_size= 11,\n",
    "        font_color= \"#000000\",\n",
    "        font_family= \"Times New Roman\",\n",
    "        margin_b = 65,\n",
    "        margin_l = 60,\n",
    "        margin_r = 30,\n",
    "        margin_t = 50,\n",
    "        plot_bgcolor= \"#ffffff\",\n",
    "        # X axis properties\n",
    "        xaxis_color= \"#000000\",\n",
    "        xaxis_linecolor= \"#000000\",\n",
    "        xaxis_ticks= \"inside\",        \n",
    "        xaxis_tickfont_color= \"#000000\",\n",
    "        xaxis_tickfont_family= \"Times New Roman\",\n",
    "        xaxis_mirror= True,\n",
    "        xaxis_showline= True,\n",
    "        xaxis_showgrid= False,\n",
    "        # Y axis properties\n",
    "        yaxis_color= \"#000000\",\n",
    "        yaxis_linecolor= \"#000000\",\n",
    "        yaxis_ticks= \"inside\",\n",
    "        yaxis_tickfont_color= \"#000000\",\n",
    "        yaxis_tickfont_family= \"Times New Roman\",\n",
    "        yaxis_mirror= True,\n",
    "        yaxis_showline= True,\n",
    "        yaxis_showgrid= False,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize & Check step value.\n",
    "def eval_step(x, step_ini, param_A, param_alpha):\n",
    "    step = step_ini / ((x + param_A)**param_alpha)\n",
    "    return step\n",
    "\n",
    "iter_opti = list(range(1,201))\n",
    "step = list(map(lambda x: eval_step(x, step_ini= 220, param_A= 50, param_alpha= 0.602), iter_opti))\n",
    "\n",
    "fig_step = go.Figure()\n",
    "\n",
    "fig_step.add_trace(\n",
    "    go.Scatter(\n",
    "        x= iter_opti,\n",
    "        y= step,\n",
    "        line_color = \"#000000\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig_step.update_layout(\n",
    "    title= \"Step Changes\",\n",
    "    xaxis_title= \"Number Iteration\",\n",
    "    yaxis_title= \"Step Value [NrVeh/hr]\",\n",
    "    width= 500,\n",
    "    height= 350,\n",
    "    template= tempelete_01_white,\n",
    ")\n",
    "\n",
    "fig_step.update_xaxes(\n",
    "    range= [0, 200]\n",
    ")\n",
    "\n",
    "fig_step.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize & Check perturbation value.\n",
    "def eval_perturb(x, perturb_ini, param_gamma):\n",
    "    perturb = perturb_ini / (x**param_gamma)\n",
    "    return perturb\n",
    "\n",
    "\n",
    "iter_opti = list(range(1,201))\n",
    "perturb = list(map(lambda x: eval_perturb(x, perturb_ini= 0.5, param_gamma=0.02), iter_opti))\n",
    "\n",
    "fig_perturb = go.Figure()\n",
    "\n",
    "fig_perturb.add_trace(\n",
    "    go.Scatter(\n",
    "        x= iter_opti,\n",
    "        y= perturb,\n",
    "        line_color = \"#000000\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig_perturb.update_layout(\n",
    "    title= \"Perturbing Changes\",\n",
    "    xaxis_title= \"Number Iteration\",\n",
    "    yaxis_title= \"Perturbing Value [NrVeh/hr]\",\n",
    "    width= 500,\n",
    "    height= 350,\n",
    "    template= tempelete_01_white,\n",
    ")\n",
    "\n",
    "fig_perturb.update_xaxes(\n",
    "    range= [0, 200]\n",
    ")\n",
    "\n",
    "fig_perturb.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SPSA object.\n",
    "spsa_sumo = pca_spsa(\n",
    "    in_fl_step_ini= 4, in_fl_param_a= 50, in_fl_param_alpha= 0.602,\n",
    "    in_fl_perturb_ini= 0.5, in_fl_param_gamma= 0.03, \n",
    "    in_int_iter_gradi= 1, in_int_iter_opti= 1, \n",
    "    in_lv_seg_step= False, in_lv_seg_perturb= False, in_int_seg_size= 5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get iterating numbers.\n",
    "int_nr_iter_opti = spsa_sumo.int_iter_opti\n",
    "int_nr_iter_gradi = spsa_sumo.int_iter_gradi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import true od matrix.\n",
    "str_path_od_true = \"./data_tabular/true_od_v02.csv\"\n",
    "spsa_sumo.read_od_true(str_path_od_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import biased od matrix.\n",
    "str_path_od_base = \"./data_tabular/biased_od_v02.csv\"\n",
    "spsa_sumo.read_od_base(str_path_od_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import true flow.\n",
    "str_path_flow_true = \"./data_tabular/edge_flow_true_v02.csv\"\n",
    "spsa_sumo.read_true_flow(str_path_flow_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OD samples and make PCA object. Explaining ratio is set to 0.95.\n",
    "str_dir_od_samples = \"data_tabular/biased_od_samples\"\n",
    "spsa_sumo.read_od_samples(str_dir_od_samples)\n",
    "spsa_sumo.create_od_pca(in_fl_ex_var= 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reducted array from base OD matrix.\n",
    "spsa_sumo.pca_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure time.\n",
    "start_time = time.time()\n",
    "# Boost gradient?\n",
    "lv_bst_gradi = False\n",
    "fac_bst_gradi = 10\n",
    "\n",
    "# LOOP_1, Optimizing Iteration.\n",
    "for iter_opti in range(1, int_nr_iter_opti + 1):\n",
    "    \n",
    "    # Parameters update for optimisation loop.\n",
    "    # Step size (a_k), Perturbation coefficient (c_k).\n",
    "    spsa_sumo.param_update(iter_opti)\n",
    "    \n",
    "    # Define empty list to collect gradient samples.\n",
    "    lst_df_gradi_tmp1 = list()\n",
    "    \n",
    "    # LOOP_2, Gradient Estimattion Iteration.\n",
    "    for iter_gradi in range(1, int_nr_iter_gradi + 1):\n",
    "        \n",
    "        # Update bernoulli random dataframe.\n",
    "        spsa_sumo.bernoulli_delta(iter_opti, iter_gradi)\n",
    "        \n",
    "        # Get reducted arr, perturbed in plus direction.\n",
    "        arr_od_reduct_plus = spsa_sumo.perturbation_plus(iter_opti, iter_gradi)\n",
    "        # Convert perturbed arr into dataframe again.\n",
    "        df_od_perturbed_plus = spsa_sumo.pca_inverse_transform(arr_od_reduct_plus)        \n",
    "        # Run simulation with perturbed OD matrix and get flow dataframe.\n",
    "        df_flow_perturbed_plus = pca_spsa.sim_sumo_get_flow(iter_opti, iter_gradi, df_od_perturbed_plus)\n",
    "        # Get Normalized RMSE with true flow value.\n",
    "        gof_plus = pca_spsa.n_Rmse(spsa_sumo.df_true_flow, df_flow_perturbed_plus)\n",
    "        print(f\"        gof_plus: {gof_plus}, Iteration_{iter_opti}_{iter_gradi}.\")\n",
    "        \n",
    "        # Get reducted arr, perturbed in minmus direction.\n",
    "        arr_od_reduct_minus = spsa_sumo.perturbation_minus(iter_opti, iter_gradi)\n",
    "        # Convert perturbed arr into dataframe again.\n",
    "        df_od_perturbed_minus = spsa_sumo.pca_inverse_transform(arr_od_reduct_minus)\n",
    "        # Run simulation with perturbed OD matrix and get flow dataframe.\n",
    "        df_flow_perturbed_minus = pca_spsa.sim_sumo_get_flow(iter_opti, iter_gradi, df_od_perturbed_minus)\n",
    "        # Get Normalized RMSE with true flow value.\n",
    "        gof_minus = pca_spsa.n_Rmse(spsa_sumo.df_true_flow, df_flow_perturbed_minus)\n",
    "        print(f\"        gof_minus: {gof_minus}, Iteration_{iter_opti}_{iter_gradi}.\")\n",
    "        \n",
    "        # Calculate sample gradient and store it in list.\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            arr_gradi_tmp2 = (gof_plus - gof_minus) / (2*spsa_sumo.fl_perturb*spsa_sumo.arr_bernoulli)\n",
    "        lst_df_gradi_tmp1.append(arr_gradi_tmp2)\n",
    "    \n",
    "    # Calculate mean value of smaple gradients.\n",
    "    arr_gradi_mean_tmp1 = sum(lst_df_gradi_tmp1) / len(lst_df_gradi_tmp1)\n",
    "    if lv_bst_gradi:\n",
    "        arr_gradi_mean_tmp1 = arr_gradi_mean_tmp1 * fac_bst_gradi\n",
    "    spsa_sumo.lst_gradi.append(arr_gradi_mean_tmp1)\n",
    "    print(f\"    Gradient estimation is ready. Iteration_{iter_opti}\")\n",
    "    \n",
    "    # Minimizing with segmented step size value.\n",
    "    # OD matrix will be adjusted in opposite direction of loss funtion gradient.\n",
    "    spsa_sumo.minimization_loss(iter_opti)\n",
    "    spsa_sumo.df_od = spsa_sumo.pca_inverse_transform(spsa_sumo.arr_od_reduct)    \n",
    "    df_flow_min = pca_spsa.sim_sumo_get_flow(iter_opti, 999, spsa_sumo.df_od)\n",
    "    nRmse_min = pca_spsa.n_Rmse(spsa_sumo.df_true_flow, df_flow_min)\n",
    "    spsa_sumo.lst_nRmse.append(nRmse_min)\n",
    "    \n",
    "    if iter_opti == 1:\n",
    "        spsa_sumo.nRmse_best = nRmse_min\n",
    "        spsa_sumo.df_flow_best = df_flow_min\n",
    "        spsa_sumo.df_od_best = spsa_sumo.df_od\n",
    "    else:\n",
    "        if nRmse_min < spsa_sumo.nRmse_best:\n",
    "            spsa_sumo.nRmse_best = nRmse_min\n",
    "            spsa_sumo.df_flow_best = df_flow_min\n",
    "            spsa_sumo.df_od_best = spsa_sumo.df_od\n",
    "    \n",
    "    # Make time stamp.\n",
    "    time_epoch = time.time() - start_time\n",
    "    spsa_sumo.lst_time_epoch.append(int(time_epoch))\n",
    "    \n",
    "    print(f\"    Iteration_{iter_opti}/{int_nr_iter_opti}: nRMSE {nRmse_min}\")\n",
    "    print(f\"    Best nRMSE so far: {spsa_sumo.nRmse_best}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
